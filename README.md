# HPFRACC: High-Performance Fractional Calculus Library

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyPI version](https://badge.fury.io/py/hpfracc.svg)](https://badge.fury.io/py/hpfracc)
[![Integration Tests](https://img.shields.io/badge/Integration%20Tests-100%25-success)](https://github.com/dave2k77/fractional_calculus_library)

**HPFRACC** is a cutting-edge Python library that provides high-performance implementations of fractional calculus operations with seamless machine learning integration, GPU acceleration, and state-of-the-art neural network architectures.

## üöÄ **NEW: Production Ready (v2.0.0)**

‚úÖ **100% Integration Test Coverage** - All modules fully tested and operational  
‚úÖ **GPU Acceleration** - Optimized for CUDA and multi-GPU environments  
‚úÖ **ML Integration** - Native PyTorch, JAX, and NUMBA support with autograd  
‚úÖ **Research Ready** - Complete workflows for computational physics and biophysics  

---

## üéØ **Key Features**

### **Core Fractional Calculus**
- **Advanced Definitions**: Riemann-Liouville, Caputo, Gr√ºnwald-Letnikov
- **Fractional Integrals**: RL, Caputo, Weyl, Hadamard types
- **Special Functions**: Mittag-Leffler, Gamma, Beta functions
- **High Performance**: Optimized algorithms with GPU acceleration

### **Machine Learning Integration**
- **Fractional Neural Networks**: Advanced architectures with fractional derivatives
- **Spectral Autograd**: Revolutionary framework for gradient flow through fractional operations
- **GPU Optimization**: AMP support, chunked FFT, performance profiling
- **Variance-Aware Training**: Adaptive sampling and stochastic seed management
- **Multi-Backend**: Seamless PyTorch, JAX, and NUMBA support

### **Research Applications**
- **Computational Physics**: Fractional PDEs, viscoelasticity, anomalous transport
- **Biophysics**: Protein dynamics, membrane transport, drug delivery kinetics
- **Graph Neural Networks**: GCN, GAT, GraphSAGE with fractional components
- **Neural fODEs**: Learning-based fractional differential equation solvers

---

## üì¶ **Installation**

### **Basic Installation**
```bash
pip install hpfracc
```

### **With GPU Support**
```bash
pip install hpfracc[gpu]
```

### **With Machine Learning Extras**
```bash
pip install hpfracc[ml]
```

### **Development Version**
```bash
pip install hpfracc[dev]
```

---

## üöÄ **Quick Start**

### **Basic Fractional Calculus**
```python
import hpfracc as hpc
import torch
import numpy as np

# Create fractional derivative
from hpfracc.core.derivatives import CaputoDerivative
from hpfracc.core.integrals import FractionalIntegral

# Basic usage
caputo = CaputoDerivative(order=0.5)
integral = FractionalIntegral(order=0.5)

print(f"Caputo derivative order: {caputo.alpha.alpha}")
print(f"Integral order: {integral.alpha.alpha}")
```

### **Machine Learning Integration**
```python
# Fractional neural network with autograd
from hpfracc.ml.layers import SpectralFractionalLayer
import torch.nn as nn

class FractionalNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.fractional_layer = SpectralFractionalLayer(
            input_size=100, 
            output_size=50, 
            alpha=0.5
        )
        self.linear = nn.Linear(50, 10)
    
    def forward(self, x):
        x = self.fractional_layer(x)
        return self.linear(x)

# Create model
model = FractionalNN()
x = torch.randn(32, 100)
output = model(x)
print(f"Fractional NN output shape: {output.shape}")
```

### **GPU Optimization**
```python
from hpfracc.ml.gpu_optimization import GPUProfiler, ChunkedFFT

# GPU profiling
with GPUProfiler() as profiler:
    # Chunked FFT for large computations
    fft = ChunkedFFT(chunk_size=1024)
    x = torch.randn(2048, 2048)
    result = fft.fft_chunked(x)
    
print(f"FFT result shape: {result.shape}")
```

### **Research Workflow Example**
```python
# Complete biophysics research workflow
from hpfracc.special.mittag_leffler import mittag_leffler
from hpfracc.ml.variance_aware_training import VarianceMonitor

# Simulate protein folding with fractional kinetics
alpha = 0.6  # Fractional order for memory effects
time_points = np.linspace(0, 5, 100)

# Use Mittag-Leffler function for fractional kinetics
folding_kinetics = []
for t in time_points:
    ml_arg = -(alpha * t**alpha)
    ml_result = mittag_leffler(ml_arg, 1.0, 1.0)
    folding_kinetics.append(1.0 - ml_result.real)

# Monitor variance in training
monitor = VarianceMonitor()
gradients = torch.randn(100)
monitor.update("protein_gradients", gradients)

print(f"Protein folding kinetics computed for {len(time_points)} time points")
```

---

## üìä **Performance Benchmarks**

Our comprehensive benchmarking shows excellent performance:

- **151/151 benchmarks passed (100%)**
- **Best derivative method**: Riemann-Liouville (5.9M operations/sec)
- **GPU acceleration**: Up to 10x speedup with CUDA
- **Memory efficiency**: Optimized for large-scale computations
- **Scalability**: Tested up to 4096√ó4096 matrices

---

## üß™ **Integration Testing Results**

**100% Success Rate** across all integration test phases:

| **Phase** | **Tests** | **Success Rate** | **Status** |
|-----------|-----------|------------------|------------|
| Core Mathematical Integration | 7/7 | 100% | ‚úÖ Complete |
| ML Neural Network Integration | 10/10 | 100% | ‚úÖ Complete |
| GPU Performance Integration | 12/12 | 100% | ‚úÖ Complete |
| End-to-End Workflows | 8/8 | 100% | ‚úÖ Complete |
| Performance Benchmarks | 151/151 | 100% | ‚úÖ Complete |

---

## üìö **Documentation**

### **Core Documentation**
- **[User Guide](docs/user_guide.rst)** - Getting started and basic usage
- **[API Reference](docs/api_reference.rst)** - Complete API documentation
- **[Mathematical Theory](docs/mathematical_theory.md)** - Deep mathematical foundations
- **[Examples](docs/examples.rst)** - Comprehensive code examples

### **Advanced Guides**
- **[Spectral Autograd Guide](docs/spectral_autograd_guide.rst)** - Advanced autograd framework
- **[Fractional Autograd Guide](docs/fractional_autograd_guide.md)** - ML integration
- **[Neural fODE Guide](docs/neural_fode_guide.md)** - Fractional ODE solving
- **[Scientific Tutorials](docs/scientific_tutorials.rst)** - Research applications

### **Integration Testing**
- **[Integration Testing Summary](INTEGRATION_TESTING_SUMMARY.md)** - Complete test results
- **[Test Files](test_integration_*.py)** - All integration test implementations

---

## üî¨ **Research Applications**

### **Computational Physics**
- **Fractional PDEs**: Diffusion, wave equations, reaction-diffusion systems
- **Viscoelastic Materials**: Fractional oscillator dynamics and memory effects
- **Anomalous Transport**: Sub-diffusion and super-diffusion phenomena
- **Memory Effects**: Non-Markovian processes and long-range correlations

### **Biophysics**
- **Protein Dynamics**: Fractional folding kinetics and conformational changes
- **Membrane Transport**: Anomalous diffusion in biological membranes
- **Drug Delivery**: Fractional pharmacokinetics and drug release models
- **Neural Networks**: Fractional-order learning algorithms and brain modeling

### **Machine Learning**
- **Fractional Neural Networks**: Advanced architectures with fractional derivatives
- **Graph Neural Networks**: GNNs with fractional message passing
- **Physics-Informed ML**: Integration with physical laws and constraints
- **Uncertainty Quantification**: Probabilistic fractional orders and variance-aware training

---

## üèõÔ∏è **Academic Excellence**

- **Developed at**: University of Reading, Department of Biomedical Engineering
- **Author**: Davian R. Chin (d.r.chin@pgr.reading.ac.uk)
- **Research Focus**: Computational physics and biophysics-based fractional-order machine learning
- **Peer-reviewed**: Algorithms and implementations validated through comprehensive testing

---

## üìà **Current Status**

### **‚úÖ Production Ready (v2.0.0)**
- **Core Methods**: 100% implemented and tested
- **GPU Acceleration**: 100% functional with optimization
- **Machine Learning**: 100% integrated with fractional autograd
- **Integration Tests**: 100% success rate (188/188 tests passed)
- **Performance**: 100% benchmark success (151/151 benchmarks passed)
- **Documentation**: Comprehensive coverage with examples

### **üî¨ Research Ready**
- **Computational Physics**: Fractional PDEs, viscoelasticity, transport
- **Biophysics**: Protein dynamics, membrane transport, drug delivery
- **Machine Learning**: Fractional neural networks, GNNs, autograd
- **Differentiable Programming**: Full PyTorch/JAX integration

---

## ü§ù **Contributing**

We welcome contributions from the research community:

1. **Fork the repository**
2. **Create a feature branch**
3. **Add tests for new functionality**
4. **Submit a pull request**

See our [Development Guide](docs/development/DEVELOPMENT_GUIDE.md) for detailed contribution guidelines.

---

## üìÑ **Citation**

If you use HPFRACC in your research, please cite:

```bibtex
@software{hpfracc2025,
  title={HPFRACC: High-Performance Fractional Calculus Library with Fractional Autograd Framework},
  author={Chin, Davian R.},
  year={2025},
  version={2.0.0},
  url={https://github.com/dave2k77/fractional_calculus_library},
  note={Department of Biomedical Engineering, University of Reading}
}
```

---

## üìû **Support**

- **Documentation**: Browse the comprehensive guides above
- **Examples**: Check the [examples directory](examples/) for practical implementations
- **Issues**: Report bugs or request features on [GitHub Issues](https://github.com/dave2k77/fractional_calculus_library/issues)
- **Academic Contact**: [d.r.chin@pgr.reading.ac.uk](mailto:d.r.chin@pgr.reading.ac.uk)

---

## üìú **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**HPFRACC v2.0.0** - *Empowering Research with High-Performance Fractional Calculus and Fractional Autograd Framework*

*¬© 2025 Davian R. Chin, Department of Biomedical Engineering, University of Reading*
