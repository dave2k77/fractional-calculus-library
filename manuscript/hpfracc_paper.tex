\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{url}
\usepackage{listings}
\lstdefinelanguage{dockerfile}{
  keywords={FROM, RUN, CMD, LABEL, MAINTAINER, EXPOSE, ENV, ADD, COPY, ENTRYPOINT, VOLUME, USER, WORKDIR, ARG, ONBUILD, STOPSIGNAL, HEALTHCHECK, SHELL},
  sensitive=true,
  comment=[l|\#],
  morestring=[b]"
}
\usepackage{xcolor}

% Define Dockerfile language for listings
\lstdefinelanguage{dockerfile}{
  keywords={FROM, RUN, CMD, LABEL, MAINTAINER, EXPOSE, ENV, ADD, COPY, ENTRYPOINT, VOLUME, USER, WORKDIR, ARG, ONBUILD, STOPSIGNAL, HEALTHCHECK, SHELL},
  sensitive=true,
  comment=[l]{\#},
  morestring=[b]",
  morestring=[b]'
}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[english]{babel}
\newcommand{\hpfracc}{\texttt{hpfracc}}
% Bibliography style for Harvard referencing
\bibliographystyle{agsm}

\title{\texttt{hpfracc}: A High-Performance Fractional Calculus Library with Machine Learning Integration and Spectral Autograd Framework}

\author{
Davian R. Chin$^{1,2}$ \\
\small $^{1}$Department of Biomedical Engineering, University of Reading, Reading, UK \\
\small $^{2}$Email: d.r.chin@pgr.reading.ac.uk
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
We present \texttt{hpfracc} (High-Performance Fractional Calculus), a comprehensive Python library that resolves the fundamental challenge of gradient flow through fractional derivatives in neural networks. The core innovation is a novel \textbf{spectral autograd framework} that transforms non-local fractional operations into local operations in the frequency domain, enabling the first practical implementation of automatic differentiation for fractional operators. Our approach leverages Mellin transforms, fractional FFT, and spectral domain chain rules to achieve computational efficiency whilst maintaining mathematical rigor. The framework provides comprehensive implementations of classical fractional operators (Riemann-Liouville, Caputo, Gr√ºnwald-Letnikov) with rigorous convergence proofs, error bounds, and stability analysis. Key computational advances include: (1) spectral domain fractional chain rule with O(N log N) complexity; (2) stochastic memory sampling with variance reduction techniques; (3) probabilistic fractional orders with uncertainty quantification; and (4) GPU-optimised implementations achieving 4.67x speedup over existing libraries. We demonstrate superior performance in neural network training with proper gradient flow (2.0x smaller gradients, better convergence) and provide extensive validation against analytical solutions. The framework is production-ready with comprehensive testing, robust MKL FFT error handling, multi-backend support (PyTorch, JAX, NUMBA), and open-source availability, making it suitable for applications in computational physics, biomedical engineering, and scientific computing.
\end{abstract}

% Include all sections
\input{sections/01_introduction}

\input{sections/02_theoretical_foundations}

\input{sections/03_literature_review}

\input{sections/04_framework_architecture}

\input{sections/05_implementation_details}

\input{sections/06_experimental_results}

\input{sections/07_discussion_future_work}

\input{sections/08_conclusion}

% Appendices
\appendix
\input{sections/appendix_a_installation}
\input{sections/appendix_b_benchmarks}
\input{sections/appendix_c_performance}

% Bibliography
\bibliography{references}

\end{document}
